
def full_evaluate(
    question: str,
    correct_answer: str,
    relevant_contexts: list[str],
    rag_answer: str,
    rag_contexts: list[str],
) -> tuple[float, float, float, float]:
    """
    Evaluate the RAG architecture on the file.

    Args:
        question (str): The question asked.
        correct_answer (str): The correct answer to the question.
        relevant_contexts (list[str]): The relevant contexts for the question.
        rag_answer (str): The answer generated by the RAG architecture.
        rag_contexts (list[str]): The contexts used by the RAG architecture to generate the answer.

    Returns:
        tuple[float, float, float, float]: A tuple containing the accuracy, faithfulness, context recall, and context precision.
    """
    # Calculate accuracy
    accuracy = 1.0 if rag_answer == correct_answer else 0.0

    # Calculate faithfulness
    faithfulness = 1.0 if any(context in rag_answer for context in relevant_contexts) else 0.0

    # Calculate context recall
    context_recall = len(set(rag_contexts) & set(relevant_contexts)) / len(relevant_contexts)

    # Calculate context precision
    context_precision = len(set(rag_contexts) & set(relevant_contexts)) / len(rag_contexts)

    return accuracy, faithfulness, context_recall, context_precision