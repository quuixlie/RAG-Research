import os
from rag.llms.llm_factory import LLMFactory
from metrics.answer_relevancy import answer_relevancy


def full_evaluate(
    question: str,
    correct_answer: str,
    relevant_contexts: list[str],
    rag_answer: str,
    rag_contexts: list[str],
    evaluation_llm_name: str,
    llm_kwargs: dict,
) -> tuple[float, float, float, float, float]:
    """
    Evaluate the RAG architecture on the file.

    Args:
        question (str): The question asked.
        correct_answer (str): The correct answer to the question.
        relevant_contexts (list[str]): The relevant contexts for the question.
        rag_answer (str): The answer generated by the RAG architecture.
        rag_contexts (list[str]): The contexts used by the RAG architecture to generate the answer.

    Returns:
        tuple[float, float, float, float, float]: A tuple containing the accuracy, faithfulness, context recall, and context precision, hallucination.
    """
    llm_name = evaluation_llm_name

    # Create the LLM
    llm = LLMFactory(llm_name, **llm_kwargs)

    accuracy =  answer_relevancy(
        question=question,
        answer=rag_answer,
        correct_answer=correct_answer,
        llm=llm,
    )
    faithfulness = 0.0
    context_recall = 0.0
    context_precision = 0.0

    return accuracy, faithfulness, context_recall, context_precision