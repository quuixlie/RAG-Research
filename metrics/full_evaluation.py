import os
from rag.llms.llm_factory import LLMFactory
from metrics.answer_relevancy import answer_relevancy
from metrics.context_precision import context_precision
from metrics.context_recall import context_recall
from metrics.faithfulness import faithfulness


def full_evaluate(
    question: str,
    correct_answer: str,
    relevant_contexts: list[str],
    rag_answer: str,
    rag_contexts: list[str],
    embedder_name: str,
    embedder_kwargs: dict,
    evaluation_llm_name: str,
    llm_kwargs: dict,
) -> tuple[float, float, float, float, float]:
    """
    Evaluate the RAG architecture on the file.

    Args:
        question (str): The question asked.
        correct_answer (str): The correct answer to the question.
        relevant_contexts (list[str]): The relevant contexts for the question.
        rag_answer (str): The answer generated by the RAG architecture.
        rag_contexts (list[str]): The contexts used by the RAG architecture to generate the answer.
        embedder_name (str): The name of the embedder to use.
        embedder_kwargs (dict): The arguments for the embedder.
        evaluation_llm_name (str): The name of the LLM to use for evaluation.
        llm_kwargs (dict): The arguments for the LLM.

    Returns:
        tuple[float, float, float, float, float]: A tuple containing the accuracy, faithfulness, context recall, and context precision, hallucination.
    """
    llm_name = evaluation_llm_name

    # Create the LLM
    llm = LLMFactory(llm_name, **llm_kwargs)

    accuracy =  answer_relevancy(
        question=question,
        answer=rag_answer,
        correct_answer=correct_answer,
        llm=llm,
    )
    faithfuln = faithfulness(
        question=question,
        answer=rag_answer,
        rag_contexts=rag_contexts,
        llm=llm
    )
    context_rec = context_recall(
        relevant_contexts=relevant_contexts,
        rag_contexts=rag_contexts,
        similarity_threshold=0.7,
        embedder_name=embedder_name,
        embedder_kwargs=embedder_kwargs,
    )

    context_prec = context_precision(
        question=question,
        rag_contexts=rag_contexts,
        correct_answer=correct_answer,
        llm=llm
    )

    return accuracy, faithfuln, context_rec, context_prec